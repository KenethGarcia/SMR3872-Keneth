{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Thinking in Parallel: Parallel Programming 101\n",
    "\n",
    "As you know, the idea of parallel programming consists on divide the work of a single problem in a lot of tiny problems that can be solved at the same time. This is a very powerful idea, but it is not always easy to implement. In this section we will see some of the most common ways to implement parallel programming. It involves a lot of concepts, related with the scaling relations and the system size of the problem.\n",
    "\n",
    "In Parallel thinking, we will need to consider a few ideas:\n",
    "\n",
    "1. Practical experience is most important\n",
    "2. Leveraging solutions from others is more important than inventing new ones\n",
    "3. A good solution today is more worth than a perfect solution tomorrow\n",
    "4. The best day to develop is using a readable and maintainable code\n",
    "\n",
    "In a workstation, all the cores have access to the same shared memory. However, in a cluster, the memory is distributed. This means that the cores can not access to the same memory. This is a very important concept, because it will determine the way we will implement the parallel programming. In a cluster, speed of the algorithm can depend on the distance between the cores and the memory. This is called the latency. In a workstation, the latency is very small, but in a cluster, the latency can be very large. This is why we need to consider the locality of the memory.\n",
    "\n",
    "In a cluster, the cores are connected by a network. This network can be a bottleneck for the speed of the algorithm. This is why we need to consider the bandwidth of the network. The use of fewer cores is better than the use of more cores, if the bandwidth is not enough.\n",
    "\n",
    "Remember that it is widely used to measure the performance of an algorithm in terms of the number of operations per second. This is called the FLOPS (Floating Point Operations Per Second). This is a very important concept, because it will determine the way we will implement the parallel programming. There are also a concept called peak performance, related with the maximum number of FLOPS that can be achieved by a computer (it can't be never reached, due to storage problems). This is a very important concept, because it will determine the way we will implement the parallel programming. The peak performance is usually measured in GFLOPS (GigaFLOPS, 10^9 FLOPS) or TFLOPS (TeraFLOPS, 10^12 FLOPS). \n",
    "\n",
    "On the other hand, there are alternative of sustained performance measuring, such as the HPL (High Performance Linpack) benchmark. This is a very important concept, because it will determine the way we will implement the parallel programming. For example, Top500 uses Linpack to measure its performance, by applying Linear Algebra.\n",
    "\n",
    "On software, the performance estimation is related with scaling. We say that an application is strong scalable if the execution time is independent of the number of cores. We say that an application is weak scalable if the execution time is proportional to the number of cores. This is a very important concept, because it will determine the way we will implement the parallel programming. In general, we want to have a strong scalable application, but it is not always possible. This is a very important concept, because it will determine the way we will implement the parallel programming. For example, if we have a problem that can be divided in 4 parts, and we have 4 cores, we will have a strong scalable application. However, if we have a problem that can be divided in 4 parts, and we have 8 cores, we will have a weak scalable application. This is a very important concept, because it will determine the way we will implement the parallel programming. In general, we want to have a strong scalable application, but it is not always possible. This performance is usually estimated using the Linpack Benchmark, where efficient algorithms reach a peak of 50-90% of the peak performance.\n",
    "\n",
    "# Amdahl's Law\n",
    "\n",
    "The Amdahl's Law state that the speedup of a parallel program is limited by the sequential fraction of the program. This is a very important concept, because it will determine the way we will implement the parallel programming. This means that if we have a program that has a sequential part of 10%, the maximum speedup we can achieve is 10x. This is a very important concept, because it will determine the way we will implement the parallel programming. This is why we need to consider the locality of the memory. However, this law does not consider the overhead of the algorithm, and assumes perfect scaling.\n",
    "\n",
    "# Functional Parallelism\n",
    "\n",
    "In functional parallelism, each task is performed differently by the cores. However, the tasks are independent.\n",
    "\n",
    "# Data Parallelism\n",
    "\n",
    "In data parallelism, each task is performed in the same way by the cores. It means that the task is distributed among the cores.\n",
    "\n",
    "# Load Imbalance\n",
    "\n",
    "In parallelism, it is important to note that diferent tasks can take a different amount of time. It represents the load imbalance, where it is important to distribute the tasks in a way that the cores are always working, even if they finished a previous task before the others.\n",
    "\n",
    "# Synchronization\n",
    "\n",
    "It is important to note when start the parallelism task and when finish it. This is called synchronization. It is important to note that the synchronization can be done in a lot of ways, and it is important to choose the best one for each case. \n",
    "\n",
    "# Distributed vs Replicated Data\n",
    "\n",
    "In parallel programming, there can be two types of data to implement the algorithm. The first one is the distributed data, where each core has a part of the data. The second one is the replicated data, where each core has all the data. It is important to note that the distributed data is usually faster, but it is more difficult to implement. \n",
    "\n",
    "In Distributed data systems, it is important to state the size of the data block in sparse problems. Without a ideal control on the domain composition, it is possible to get a load imbalance. For example, in a particle calculation, the division of particles in each box of calculations can be critical to enhance the time execution (recursive bisection)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "641efe5cabcf19a5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Distributed Parallel Programming using MPI\n",
    "\n",
    "MPI (Message Passing Interface) is a standard for distributed parallel programming. It is a library that allows to implement parallel programming in a cluster. It is important to note that MPI is not a language, but a library. This means that it can be used in a lot of languages, such as C, C++, Fortran, Python, etc. \n",
    "\n",
    "In MPI, the cores are called processes. Each process has a rank, that is a number that identifies the process. It is important to note that the rank is unique for each process. This means that there are no two processes with the same rank.\n",
    "\n",
    "In MPI, there is a communicator size and process rank. The communicator size is the number of processes in the communicator for MPI. The process rank is the rank of the process in the communicator. By default, the MPI_COMM_WORLD communicator is available and contains all the processor allocated by mpirun. Its size states how many tasks are there in total:\n",
    "```\n",
    "CALL MPI_COMM_SIZE(MPI_COMM_WORLD, nprocs, ierr)  # It defines the size of the cpus used per node\n",
    "```\n",
    "where nprocs is the number of processes in the communicator and ierr is the error code. On the other hand, Rank identifies the calling process in the communicator:\n",
    "```\n",
    "CALL MPI_COMM_RANK(MPI_COMM_WORLD, myid, ierr)  # It set the ID of each node used\n",
    "```\n",
    "where myid is the rank of the process in the communicator and ierr is the error code.\n",
    "\n",
    "**Note: It is essential to call \"MPI_INIT\" before any other MPI call. It is also essential to call \"MPI_FINALIZE\" before the end of the program.**\n",
    "\n",
    "# Messages\n",
    "\n",
    "In MPI, a message is an array of elements of a certain type. MPI defines a sample of constants to define certain types of datatypes, such as MPI_INTEGER, MPI_REAL, MPI_DOUBLE_PRECISION, MPI_COMPLEX, MPI_CHARACTER, MPI_LOGICAL, MPI_BYTE, MPI_PACKED, MPI_2INTEGER, MPI_2REAL, MPI_2DOUBLE_PRECISION, MPI_2COMPLEX, MPI_2INTEGER, MPI_2REAL, etc. It is important to note that MPI also allows to define new datatypes, using the MPI_TYPE_CONTIGUOUS, MPI_TYPE_VECTOR, MPI_TYPE_INDEXED, MPI_TYPE_CREATE_SUBARRAY, MPI_TYPE_CREATE_RESIZED, MPI_TYPE_CREATE_STRUCT, MPI_TYPE_CREATE_HINDEXED, MPI_TYPE_CREATE_HVECTOR, MPI_TYPE_CREATE_INDEXED_BLOCK, MPI_TYPE_CREATE_F90_REAL, MPI_TYPE_CREATE_F90_CO. Also, the messages have a standard structure in MPI, that is defined by the following parameters:\n",
    "\n",
    "- An envelope consisting of source, destination, tag and communicator. These define the message destination, source, type and the communicator where the message is sent.\n",
    "- A body consisting of a buffer, count, and datatype. These define the message data, the number of elements and the type of the elements.\n",
    "\n",
    "This type of operation is performed using Broadcast MPI function, in the following way:\n",
    "```\n",
    "CALL MPI_BCAST(buffer, count, datatype, root, comm, ierr)  # It sends a message from the root to all the processes in the communicator\n",
    "```\n",
    "where buffer is the initial address of send buffer, count is the number of elements in send buffer, datatype is the datatype of each send buffer element, root is the rank of sending process, comm is the communicator, and ierr is the error code.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f59f07fa1152380f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
